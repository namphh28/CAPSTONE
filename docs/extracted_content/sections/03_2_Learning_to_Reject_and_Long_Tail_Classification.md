# 2. Learning to Reject and Long-Tail Classification

MEETS LONG-TAIL LEARNING Harikrishna Narasimhan, Aditya Krishna Menon, Wittawat Jitkrittum Neha Gupta, Sanjiv Kumar Google Research {hnarasimhan, adityakmenon, wittawat, nehagup, sanjivk}@google.com ABSTRACT Learning to reject (L2R) is a classical problem where one seeks a classiﬁer capable of abstaining on low-conﬁdence samples. Most prior work on L2R has focused on minimizing the standard misclassiﬁcation error. However, in many real-world applications, the label distribution is highly imbalanced, necessitating alternate evaluation metrics such as the balanced error or the worst-group error that enforce equitable performance across both the head and tail classes. In this paper, we establish that traditional L2R methods can be grossly sub-optimal for such metrics, and show that this is due to an intricate dependence in the objective between the label costs and the rejector. We then derive the form of the Bayes-optimal classiﬁer and rejector for the balanced error, propose a novel plug-in approach to mimic this solution, and extend our results to general evaluation metrics. Through experiments on benchmark image classiﬁcation tasks, we show that our approach yields better trade-offs in both the balanced and worst-group error compared to L2R baselines. 1 INTRODUCTION Multi-class classiﬁcation is typically framed as learning a classiﬁer that can provide accurate predic- tions on any test sample. However, in many real-world problems, it may be preferable to allow the classiﬁer to abstain from making a prediction on low-conﬁdence samples. Learning to reject (L2R) is the problem of learning such a classiﬁer capable of abstaining on certain samples, at the expense of incurring a ﬁxed cost (Bartlett et al., 2006; El-Yaniv & Wiener, 2010; Cortes et al., 2016; Gangrade et al., 2021; Cortes et al., 2023). Common L2R approaches include conﬁdence-based thresholding or Chow’s rule (Chow, 1970), and loss-based strategies which pose the problem as an instance of cost-sensitive learning (Cortes et al., 2016; Ramaswamy et al., 2018; Ni et al., 2019; Mozannar & Sontag, 2020; Charoenphakdee et al., 2021; Verma & Nalisnick, 2022; Mao et al., 2023a). Most prior studies on L2R have focused on the goal of minimizing the standard misclassiﬁcation error. However, the misclassiﬁcation error may not be well-suited to evaluate the performance of classiﬁer when the label distribution is highly imbalanced or long-tailed (Buda et al., 2017). In such applications, one often employs evaluation metrics such as the balanced error (Brodersen et al., 2010) or the worst-group error (Sagawa et al., 2020), which enforce equitable performance across different label groups (e.g., head and tail). This raises a natural, but surprisingly under-explored question: what is an appropriate L2R mechanism for such generalised evaluation measures? In this paper, we present a formal study of the problem of L2R with general evaluation metrics. In the standard classiﬁcation setup, one typically minimizes a given evaluation measure by formulating an equivalent cost-sensitive problem (Menon et al., 2013; Koyejo et al., 2014). For example, with the balanced error metric, one may re-weight the per-class errors by the inverse class priors. Similarly, many commonly used classiﬁcation metrics can be reduced to minimizing a cost-sensitive error with ﬁxed label costs (Narasimhan et al., 2015b). However, applying these reduction techniques to the L2R setup is not straightforward. In particular, even with a metric as simple as the balanced classiﬁcation error, the resulting label costs are no longer constants, and have an intricate dependence on the rejection mechanism. We characterize the optimal solution for this non-trivial formulation, propose novel plug-in approaches to mimic the solution, and demonstrate their efﬁcacy in experiments. In summary, we make the following contributions: 1
Published as a conference paper at ICLR 2024 Table 1: Summary of Bayes-optimal classiﬁer h∗and rejector r∗for different metrics. We assume a cost c for abstention. With the standard 0-1 error (row 1) and the conditional 0-1 error (row 2), the optimal rejector is a thresholding of the true class-probability of the predicted label. With the balanced error (row 3), the rejector takes a fundamentally different form, and involves all class-probabilities, with per-class coefﬁcients u, v ∈RK that are distribution-dependent. With a general evaluation metric such as the worst-group error (row 4), we have a stochastic combination of multiple classiﬁer-rejector pairs. L2R Risk h∗(x) r∗(x) Reference Standard (1) arg maxy ηy(x) maxy ηy(x) < 1 −c Chow (1970) Conditional (22) arg maxy ηy(x) maxy ηy(x) < 1 −c′ Lemma 8 (App. C) Balanced (6) arg maxy uy · ηy(x) maxy uy · ηy(x) < P j vj · ηj(x) −c Theorem 1 Generalized (14) Stochastic combination of (h, r) pairs of the form in row 3 Theorem 3 0.0 0.2 0.4 0.6 0.8 Proportion of Rejections 0.0 0.1 0.2 0.3 0.4 0.5 0.6 Balanced Error Chow's rule Plug-in [Balanced] Plug-in [Worst] (a) 0.0 0.2 0.4 0.6 0.8 Proportion of Rejections 0.0 0.1 0.2 0.3 0.4 Conditional Head Error Chow's rule Plug-in [Balanced] Plug-in [Worst] (b) 0.0 0.2 0.4 0.6 0.8 Proportion of Rejections 0.0 0.2 0.4 0.6 0.8 Conditional Tail Error Chow's rule Plug-in [Balanced] Plug-in [Worst] (c) 0.0 0.2 0.4 0.6 0.8 Proportion of Rejections 0.0 0.1 0.2 0.3 0.4 0.5 0.6 Tail Error - Head Error Chow's rule Plug-in [Balanced] Plug-in [Worst] (d) Figure 1: Comparison of balanced error as a function of proportion of samples rejected on the Image Net-LT dataset. We compare Chow’s rule with the proposed plug-in methods. We also include plots of the individual head and tail errors, and the differences between them. We designate classes with 20 or fewer samples in the training set as “tail” classes, and the remaining as “head” classes. The base classiﬁer uses a Res Net-50 architecture. Chow’s rule is seen to be substantially better on the head group compared to the tail group. In contrast, the proposed plug-in rules yield signiﬁcantly lower balanced (worst-group) error. They are also seen to yield a lower gap between the tail and head errors. (i) We ﬁrst derive the Bayes-optimal classiﬁer and rejector for the balanced error metric, and show that they have a fundamentally different form from classical baselines such as Chow’s rule (Chow, 1970), which reject samples with low prediction conﬁdence (§3, Table 1, Theorem 1). (ii) We show that vanilla modiﬁcations to Chow’s rule such as changing the loss used in the base model training are also theoretically sub-optimal for the balanced error. As an alternative, we propose a novel plug-in approach that seeks to mimic the Bayes-optimal solution without making any changes to the base model training (§4). (iii) We then extend our Bayes-optimal characterization to any evaluation metric that can be expressed as a general function of the per-class errors (Theorem 3), and as a concrete example, showcase how to extend our plug-in approach to minimize the worst-group error (§5). (iv) Through experiments on benchmark long-tailed image classiﬁcation datasets, we demonstrate that our plug-in approach yields signiﬁcantly better trade-offs than Chow’s rule, and is competitive with variants of Chow that require changes to the training process (§6). 2 LEARNING TO REJECT AND LONG-TAIL CLASSIFICATION We begin with some background material. Let X be an instance space, Y = [L] .= {1, 2, . . . , L} be the label space, and P be the underlying distribution over X × Y. Furthermore, let ηy(x) = P(y | x) denote the conditional distribution over labels. Given a training set S = {(xn, yn)}n∈[N] comprising N i.i.d. draws from P, multi-class classiﬁcation canonically seeks a classiﬁer h: X →Y with low misclassiﬁcation error R0-1(h) = P(y ̸= h(x)). We may parameterise h(x) = arg maxy′∈Y fy′(x) for a scorer f : X →RL, which is typically trained by minimizing an empirical surrogate risk on S. 2.1 LEARNING TO REJECT We are interested in settings where the classiﬁer is provided the option of abstaining on select samples. To this end, we consider the goal of learning a classiﬁer h: X →Y and a rejector r: X →{0, 1}. For a given instance x, we abstain on a sample whenever r(x) = 1, and predict h(x) otherwise. 2
Published as a conference paper at ICLR 2024 Prior literature has explored minimizing the standard misclassiﬁcation error with a constant penalty for abstaining on a sample (Cortes et al., 2016): Rrej 0-1(h, r) = P (y ̸= h(x), r(x) = 0) + c · P (r(x) = 1) . (1) Intuitively, when r chooses not to abstain, we incur the usual misclassiﬁcation error; otherwise, we incur the cost c > 0. Under mild distributional assumptions, this objective can be equivalently seen as constraining the proportion of abstentions to be within a budget, a formulation often referred to as selective classiﬁcation (Geifman & El-Yaniv, 2017; Gangrade et al., 2021). More precisely, via a Lagrangian analysis (following, e.g., the Neyman-Pearson lemma (Neyman & Pearson, 1933)), for any such abstention budget, there exists an equivalent cost c in Eq. (1); see Appendix B for details. Bayes-optimal L2R. The Bayes-optimal solution for Eq. (1) admits an intuitive form: h∗(x) = argmax y∈[L] ηy(x); r∗(x) = 1 ⇐⇒ max y∈[L] ηy(x) < 1 −c. (2) The classiﬁer abstains whenever the maximum conditional probability falls below a certain threshold, and otherwise, predicts the class with the maximum class probability. Post-hoc L2R. A classical baseline for L2R, often dubbed as Chow’s rule (Chow, 1970), seeks to mimic the rejector in Eq. (2). In practice, one may implement Chow’s rule by training a scorer f : X →RL to minimize the softmax cross-entropy (CE) loss: E(x,y)∼P [ℓce(y, f(x))] = E(x,y)∼P  log  P y′∈[L] efy′(x) −fy(x)  . (3) One then uses the learned scorer f to compute estimates py(x) ∝exp(fy(x)) of the class probabilities ηy(x), and constructs the rejector by thresholding the maximum probability maxy py(x) at 1 −c. Loss-based L2R. As an alternative to Chow’s rule, which constructs a rejector post-hoc given an existing classiﬁer, the literature has also explored the design of loss functions that jointly learn both the classiﬁer and rejector to optimize the L2R risk (Cortes et al., 2016; Geifman & El-Yaniv, 2017; Ramaswamy et al., 2018; Ni et al., 2019; Mozannar & Sontag, 2020; Charoenphakdee et al., 2021). Of these, Geifman & El-Yaniv minimize a variant of the L2R risk in Eq. (1) where the classiﬁcation error is conditioned on non-rejected samples. As shown in Appendix C, the optimal rejector for this conditional risk has the same form as Eq. (2), but uses a different (distribution-dependent) threshold. 2.2 LONG-TAIL CLASSIFICATION In many real-world applications, the label distribution is highly class imbalanced (He & Garcia, 2009), or long-tailed (Buda et al., 2017). In such setting, one may wish to evaluate performance separately on minority and majority classes. For example, a common partitioning of the classes is into head and tail classes, the primary setting of interest in this paper. More generally, let G1, . . . , GK ⊆Y denote a paritioning of the labels into K disjoint groups, with Gi ∩Gj = ∅, ∀i ̸= j and ∪k∈[K]Gk = Y. Let πk = P (y ∈Gk) denote the proportion of samples belonging to group Gk. The misclassiﬁcation error for label group Gk can then be measured as P (y ̸= h(x) | y ∈Gk). A key metric of interest in this setting is the balanced error that computes the average error across label groups (Brodersen et al., 2010; Menon et al., 2013; 2021b): Rbal(h) = 1 K X k∈[K] P (y ̸= h(x) | y ∈Gk) = 1 K X k∈[K] 1 πk · P (y ̸= h(x), y ∈Gk) . (4) In practice, one may minimize the balanced error by using a balanced version of the cross-entropy loss, implemented, e.g., through adjustments to the model logits (Menon et al., 2021a). The literature also explores a plethora of other techniques to perform well on the balanced error, including data modiﬁcations (Yin et al., 2019; Zhang et al., 2019), loss modiﬁcations (Cui et al., 2019; Cao et al., 2019; Tan et al., 2020; Jamal et al., 2020; Ren et al., 2020; Wu et al., 2020a; Deng et al., 2021; Kini et al., 2021; Wang et al., 2021), and prediction modiﬁcations (Kang et al., 2020; Zhang et al., 2021). Another evaluation metric of interest is the worst-group error, which is typically minimized through distributionally robust optimization (DRO) (Sagawa et al., 2020; Menon et al., 2021b): Rwst(h) = max k∈[K] P (y ̸= h(x) | y ∈Gk) = max k∈[K] 1 πk · P (y ̸= h(x) , y ∈Gk) . (5) 3
Published as a conference paper at ICLR 2024 Beyond the balanced (worst-group) errors, there are many other metrics popular in the class imbal- anced literature, such as the F-measure or the G-mean, which can be generally expressed as functions of the confusion matrix (Menon et al., 2013; Narasimhan et al., 2015b). When learning a stand-alone classiﬁer, minimizing these can be reduced to a cost-sensitive learning problem with constant label costs (Narasimhan et al., 2019). We see next that such a simple reduction is not possible when jointly learning a classiﬁer and rejector in an L2R setup, even with a metric as simple as the balanced error.

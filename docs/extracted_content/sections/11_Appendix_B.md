# Appendix B

for details. Bayes-optimal L2R. The Bayes-optimal solution for Eq. (1) admits an intuitive form: h∗(x) = argmax y∈[L] ηy(x); r∗(x) = 1 ⇐⇒ max y∈[L] ηy(x) < 1 −c. (2) The classiﬁer abstains whenever the maximum conditional probability falls below a certain threshold, and otherwise, predicts the class with the maximum class probability. Post-hoc L2R. A classical baseline for L2R, often dubbed as Chow’s rule (Chow, 1970), seeks to mimic the rejector in Eq. (2). In practice, one may implement Chow’s rule by training a scorer f : X →RL to minimize the softmax cross-entropy (CE) loss: E(x,y)∼P [ℓce(y, f(x))] = E(x,y)∼P  log  P y′∈[L] efy′(x) −fy(x)  . (3) One then uses the learned scorer f to compute estimates py(x) ∝exp(fy(x)) of the class probabilities ηy(x), and constructs the rejector by thresholding the maximum probability maxy py(x) at 1 −c. Loss-based L2R. As an alternative to Chow’s rule, which constructs a rejector post-hoc given an existing classiﬁer, the literature has also explored the design of loss functions that jointly learn both the classiﬁer and rejector to optimize the L2R risk (Cortes et al., 2016; Geifman & El-Yaniv, 2017; Ramaswamy et al., 2018; Ni et al., 2019; Mozannar & Sontag, 2020; Charoenphakdee et al., 2021). Of these, Geifman & El-Yaniv minimize a variant of the L2R risk in Eq. (1) where the classiﬁcation error is conditioned on non-rejected samples. As shown in
